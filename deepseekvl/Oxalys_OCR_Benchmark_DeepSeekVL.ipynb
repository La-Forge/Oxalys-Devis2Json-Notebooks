{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set Path & Install Libraries"
      ],
      "metadata": {
        "id": "wgyTshBWjr_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"DeepSeekVL\"\n",
        "input_path = \"./Devis\"\n",
        "output_path = \"./output_json_%s\"%model_name\n",
        "import os\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# os.chdir('/content/drive/MyDrive/ColabWorks/LF/Oxalys/Data')"
      ],
      "metadata": {
        "id": "YV2daIX0eAdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!sudo apt install poppler-utils\n",
        "\n",
        "# !pip install pdf2image\n",
        "# !pip install PyPDF2\n",
        "# !pip install lmdeploy\n",
        "# !pip install git+https://github.com/deepseek-ai/DeepSeek-VL.git\n",
        "# !pip install nest_asyncio"
      ],
      "metadata": {
        "id": "Q7Fwl7e-ozYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "Q33XRLSvQH84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize DeepSeek"
      ],
      "metadata": {
        "id": "LaoHjwoJj8V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lmdeploy import pipeline, TurbomindEngineConfig\n",
        "from lmdeploy.vl import load_image\n",
        "\n",
        "engine_config = TurbomindEngineConfig(cache_max_entry_count=0.3)\n",
        "pipe = pipeline('deepseek-ai/deepseek-vl-1.3b-chat', backend_config=engine_config)\n",
        "\n",
        "## Example Code for Interaction\n",
        "# image = load_image('https://raw.githubusercontent.com/open-mmlab/mmdeploy/main/tests/data/tiger.jpeg')\n",
        "# response = pipe(('describe this image', image))\n",
        "# print(response)"
      ],
      "metadata": {
        "id": "GT1qY2ZWokp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts"
      ],
      "metadata": {
        "id": "fYgKbXA6kHWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Prompts\n",
        "company_info_prompt = \"\"\"\n",
        "You are given the first page of a French quotation (devis). Extract the following:\n",
        "- Company name (nom_fournisseur)\n",
        "- Company address (adresse_fournisseur)\n",
        "\n",
        "Respond in the following JSON format:\n",
        "{\n",
        "  \"nom_fournisseur\": \"<company_name>\",\n",
        "  \"adresse_fournisseur\": \"<company_address>\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "product_info_prompt = \"\"\"\n",
        "You are given a page from a French quotation (devis). Extract all listed products. For each product, provide:\n",
        "- Product code (code_produit)\n",
        "- Product name (nom_produit)\n",
        "- Estimated volume (volume_estime)\n",
        "- Unit price excluding tax (pu_ht)\n",
        "- Total amount excluding tax (montant_ligne_ht)\n",
        "- Discount (remise) if mentioned\n",
        "\n",
        "Respond with a JSON array like this:\n",
        "[\n",
        "  {\n",
        "    \"code_produit\": \"<product_code>\",\n",
        "    \"nom_produit\": \"<product_name>\",\n",
        "    \"volume_estime\": <float>,\n",
        "    \"pu_ht\": <float>,\n",
        "    \"montant_ligne_ht\": <float>,\n",
        "    \"remise\": <float>\n",
        "  }\n",
        "]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Qd4RgI5kjsUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing"
      ],
      "metadata": {
        "id": "XhbU9B9XkJ6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Convert pdf to image\n",
        "from pdf2image import convert_from_path\n",
        "from PyPDF2 import PdfReader\n",
        "from PIL import Image\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "\n",
        "\n",
        "def is_image_pdf(pdf_path):\n",
        "    reader = PdfReader(pdf_path)\n",
        "    for page in reader.pages:\n",
        "        if '/XObject' in page['/Resources']:\n",
        "            xObject = page['/Resources']['/XObject'].get_object()\n",
        "            for obj in xObject:\n",
        "                if xObject[obj]['/Subtype'] == '/Image':\n",
        "                    return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def convert_pdf_to_images(pdf_path, output_folder):\n",
        "    if is_image_pdf(pdf_path):\n",
        "        reader = PdfReader(pdf_path)\n",
        "        base_filename = os.path.splitext(os.path.basename(pdf_path))[0]\n",
        "        image_paths = []\n",
        "\n",
        "        for i, page in enumerate(reader.pages):\n",
        "            xObject = page['/Resources']['/XObject'].get_object()\n",
        "            for obj in xObject:\n",
        "                if xObject[obj]['/Subtype'] == '/Image':\n",
        "                    image_data = xObject[obj]._data\n",
        "                    image = Image.open(io.BytesIO(image_data))\n",
        "                    image = image.resize((int(image.width * 0.8), int(image.height * 0.8)))  # 缩小 20%\n",
        "                    image_path = os.path.join(output_folder, f\"{base_filename}_page_{i+1}.png\")\n",
        "                    image.save(image_path, 'PNG')\n",
        "                    image_paths.append(image_path)\n",
        "        return image_paths\n",
        "\n",
        "    else:\n",
        "        images = convert_from_path(pdf_path)\n",
        "        base_filename = os.path.splitext(os.path.basename(pdf_path))[0]\n",
        "\n",
        "        image_paths = []\n",
        "        for i, image in enumerate(images):\n",
        "            image_filename = f\"{base_filename}_page_{i+1}.png\"\n",
        "            image_path = os.path.join(output_folder, image_filename)\n",
        "            image.save(image_path, 'PNG')\n",
        "            image_paths.append(image_path)\n",
        "\n",
        "        return image_paths"
      ],
      "metadata": {
        "id": "aR3tJnkdX2tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_company_info(llm_output):\n",
        "    company_name_pattern = r'\"nom_fournisseur\"\\s*:\\s*\"([^\"]+)\"'\n",
        "    company_address_pattern = r'\"adresse_fournisseur\"\\s*:\\s*\"([^\"]+)\"'\n",
        "\n",
        "    name_match = re.search(company_name_pattern, llm_output)\n",
        "    address_match = re.search(company_address_pattern, llm_output)\n",
        "\n",
        "    company_info = {\n",
        "        \"nom_fournisseur\": name_match.group(1) if name_match else None,\n",
        "        \"adresse_fournisseur\": address_match.group(1) if address_match else None\n",
        "    }\n",
        "\n",
        "    return company_info\n",
        "\n",
        "def extract_products_info(llm_output):\n",
        "    product_pattern = re.compile(\n",
        "        r'\\{\\s*\"code_produit\"\\s*:\\s*\"([^\"]+)\",\\s*'\n",
        "        r'\"nom_produit\"\\s*:\\s*\"([^\"]+)\",\\s*'\n",
        "        r'\"volume_estime\"\\s*:\\s*([\\d\\.]+),\\s*'\n",
        "        r'\"pu_ht\"\\s*:\\s*([\\d\\.]+),\\s*'\n",
        "        r'\"montant_ligne_ht\"\\s*:\\s*([\\d\\.]+),\\s*'\n",
        "        r'\"remise\"\\s*:\\s*([\\d\\.]+)\\s*\\}',\n",
        "        re.MULTILINE\n",
        "    )\n",
        "\n",
        "    products = []\n",
        "    for match in product_pattern.finditer(llm_output):\n",
        "        product = {\n",
        "            \"code_produit\": match.group(1),\n",
        "            \"nom_produit\": match.group(2),\n",
        "            \"volume_estime\": float(match.group(3)),\n",
        "            \"pu_ht\": float(match.group(4)),\n",
        "            \"montant_ligne_ht\": float(match.group(5)),\n",
        "            \"remise\": float(match.group(6))\n",
        "        }\n",
        "        products.append(product)\n",
        "\n",
        "    return products\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def convert_pdf_to_images(pdf_path, output_folder):\n",
        "    images = convert_from_path(pdf_path)\n",
        "    base_filename = os.path.splitext(os.path.basename(pdf_path))[0]\n",
        "\n",
        "    image_paths = []\n",
        "    for i, image in enumerate(images):\n",
        "        image_filename = f\"{base_filename}_page_{i+1}.png\"\n",
        "        image_path = os.path.join(output_folder, image_filename)\n",
        "        image.save(image_path, 'PNG')\n",
        "        image_paths.append(image_path)\n",
        "\n",
        "    return image_paths\n",
        "\n",
        "def process_pdf(pdf_path, image_folder, output_folder):\n",
        "    image_paths = convert_pdf_to_images(pdf_path, image_folder)\n",
        "    pdf_name = os.path.basename(pdf_path)\n",
        "\n",
        "    extracted_data = {\n",
        "        \"nom_fichier\": pdf_name,\n",
        "        \"nom_fournisseur\": None,\n",
        "        \"adresse_fournisseur\": None,\n",
        "        \"produits\": []\n",
        "    }\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        image = load_image(image_path)\n",
        "\n",
        "        # for page 1: company\n",
        "        if \"_page_1\" in image_path:\n",
        "            response = pipe((company_info_prompt, image))\n",
        "            company_info = extract_company_info(response.text)\n",
        "            extracted_data.update(company_info)\n",
        "\n",
        "        # for all pages: prodcut\n",
        "        response = pipe((product_info_prompt, image))\n",
        "        products_info = extract_products_info(response.text)\n",
        "        extracted_data[\"produits\"].extend(products_info)\n",
        "\n",
        "    # json\n",
        "    output_file = os.path.join(output_folder, f\"{os.path.splitext(pdf_name)[0]}.json\")\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(extracted_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"Saved to: {output_file}\")\n",
        "\n",
        "\n",
        "def process_folder(input_folder, image_folder, output_folder):\n",
        "    start_time = time.time()\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.pdf'):\n",
        "            pdf_path = os.path.join(input_folder, filename)\n",
        "            try:\n",
        "                process_pdf(pdf_path, image_folder, output_folder)\n",
        "            except Exception as e:\n",
        "                print(f\"Fail to process: {filename}, Error: {str(e)}\")\n",
        "                empty_output = {\n",
        "                    \"nom_fichier\": filename,\n",
        "                    \"nom_fournisseur\": None,\n",
        "                    \"adresse_fournisseur\": None,\n",
        "                    \"produits\": []\n",
        "                }\n",
        "                output_file = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}.json\")\n",
        "                with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(empty_output, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    print(f\"Total time for processing pdfs: {total_time:.2f} seconds\")\n",
        "\n"
      ],
      "metadata": {
        "id": "oa9Q4JpRUVSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "jgbnN4RWkTbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process_folder(input_path, 'tmp_images_folder', output_path)"
      ],
      "metadata": {
        "id": "r5Twb6KCkTFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "7dD2RL9pbZeY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}